#+OPTIONS: H:3 num:t toc:t ^:nil tex:t
#+TITLE: spark-kafka-stream
* About

** 概要

   - センサーデータ
     - 緯度経度(lon,lat),温度、湿度、酸性度、水分
   - ストリーム処理
     - 異常値検出
     - データ蓄積
   - Jupyter Lab でデータ分析
     - spark に接続
   - 特徴
     - 遠隔地のセンサ処理を仮定
     - 分散処理に適した構成

** 技術要素

   - ログ収集: [[https://www.fluentd.org/][Fluentd]]
   - 分散ストリーミング: [[https://kafka.apache.org/][Apache Kafka]]
   - 統合分析エンジン: [[https://spark.apache.org/][Apache Spark]]
   - 分散 NoSQL DB: [[https://cassandra.apache.org/][Apache Cassandra]]
   - データ分析・開発環境: [[https://jupyter.org/][Jupyter Lab]]
   - 構成: [[https://www.docker.com/][Docker]]
     
* 構成図

    #+begin_src plantuml :file fig0.png :cmdline -charset UTF-8
      !include <logos/jupyter.puml>
      !include <logos/kafka.puml>
      !include <logos/spark.puml>
      !include <logos/cassandra.puml>
      
      title 構成図
      
      skinparam monochrome true
      
      queue "<$kafka>\n sendor-data" as kafka1
      queue "<$kafka>\n joined-sendor-data" as kafka2
      queue "<$kafka>\n whc-less-sendor-data" as kafka3
      
      node "Master" {
      database "<$cassandra>" as cassandra1
      rectangle "☆\n Spark" as spark1
      }
      node "Worker1" {
      database "<$cassandra>" as cassandra2
      rectangle "☆\n Spark" as spark2
      }
      node "Worker2" {
      database "<$cassandra>" as cassandra3
      rectangle "☆\n Spark" as spark3
      }
      
      rectangle "<$jupyter>\n 分析" as jupyter
      
      fluentd -> kafka1 : 温度・湿度
      kafka1 -> spark1
      spark1 --> kafka2 : "Sensor 位置情報 Join"
      kafka2 --> kafka3 : "Window 処理"
      kafka3 -> alert : "Windows\n 平均水量不足"
      spark1 <-> cassandra1
      spark2 <-> cassandra2
      spark3 <-> cassandra3
      
      cassandra1 <-> cassandra2
      cassandra2 <--> cassandra3
      cassandra3 <--> cassandra1
      spark1 <-> spark2
      spark2 <--> spark3
      spark3 <--> spark1
      
      spark1 <-- jupyter
      
      
    #+end_src

    #+RESULTS:
    [[file:fig0.png]]

  
* 手順

** 疑似センサーデータ生成スクリプトを常時走らせる
   #+begin_quote
     * * * * * /path/to/sensor_data/execute_create_sensor_data.sh >> /path/to/sensor_data/sensor_data.log
   #+end_quote
   - wsl2 の場合は cron は働かないので、起動すること
   #+begin_sec shell
     service cron start
   #+end_src
     
** サーバ群起動
   #+begin_src shell
   docker-compose up -d
   #+end_src

* Jupyter Lab + Spark

  - アドホックデータ分析でインサイトを得る
  - sparkContext

* 機械学習処理(TODO)
  - spark.ml 利用したバッチ分析
  - 前処理
    - 特徴量の数を決める(PCA)
  - 学習
    - 特徴量抽出～モデル～パラメタ推定～特徴量選択～モデル評価と選択
    - 特徴量の組み合わせでモデル作成し精度をみる
    - AUC/RMSE
  - 予測
* 改善の余地
** TODO kubernetes に展開
** TODO Arduino などで実センサ接続
** TODO Cassandra Only DC をつくり、分析環境からオペレーショナル環境を分離する
